#!/usr/bin/env python

# Copyright 2017-2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License"). You
# may not use this file except in compliance with the License. A copy of
# the License is located at
#
#     http://aws.amazon.com/apache2.0/
#
# or in the "license" file accompanying this file. This file is
# distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF
# ANY KIND, either express or implied. See the License for the specific
# language governing permissions and limitations under the License.

# A sample training component that trains a simple scikit-learn decision tree model.
# This implementation works in File mode and makes no assumptions about the input file names.
# Input is specified as CSV with a data point in each row and the labels in the first column.

import json
import os
import sys
import traceback
from shutil import copyfile


import tensorflow as tf

from utils import commandline_util

# These are the paths to where SageMaker mounts interesting things in your container.
prefix = '/opt/ml/'
input_path = os.path.join(prefix, 'input/data')
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')
param_path = os.path.join(prefix, 'input/config/hyperparameters.json')

tfrecord_train_path = os.path.join(input_path, 'train/train.records')
tfrecord_val_path = os.path.join(input_path, 'validation/validation.records')
tfrecord_label_path = os.path.join(input_path, 'label/label_map.pbtxt')
tfrecord_config_path = os.path.join(input_path, 'config/configuration.config')
tfrecord_pretrained_checkpoint_path = os.path.join(input_path, 'checkpoint/')

# This algorithm has a single channel of input data called 'training'. Since we run in
# File mode, the input files are copied to the directory specified here.
channel_name = 'training'
training_path = os.path.join(input_path, channel_name)

# default params
training_script = '/opt/ml/code/tensorflow-models/research/object_detection/model_main.py'
freezing_script = '/opt/ml/code/tensorflow-models/research/object_detection/export_inference_graph.py'
lite_freezing_script = '/opt/ml/code/tensorflow-models/research/object_detection/export_tflite_ssd_graph.py'
lite_quant_script = '/opt/ml/code/tensorflow-models/research/object_detection/export_tflite_ssd_graph.py'


if __name__ == '__main__':
    try:
        print('Using Tensorflow version: {}'.format(tf.__version__))

        # Amazon SageMaker makes our specified hyperparameters available within the
        # /opt/ml/input/config/hyperparameters.json.
        # https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html#your-algorithms-training-algo-running-container
        with open(param_path, 'r') as tc:
            training_params = json.load(tc)

        print('Loaded training parameters: {}'.format(training_params))

        if 'num_steps' in training_params:
            num_steps_hyperparam = training_params['num_steps']
        else:
            num_steps_hyperparam = '100'

        if 'quantize' in training_params:
            quantize = bool(training_params['quantize'])
        else:
            quantize = False

        print('Setting number of steps to {}'.format(num_steps_hyperparam))
        print('Setting quantization to {}'.format(quantize))

        file_list = os.listdir(tfrecord_pretrained_checkpoint_path)
        print("Extracted checkpoint files: {}".format(file_list))

        default_params = ['--model_dir', str(model_path),
                          '--pipeline_config_path', str(tfrecord_config_path),
                          '--num_train_steps', str(num_steps_hyperparam)]
        print('Starting the training...')
        commandline_util.run_python_script(training_script, default_params)

        # freeze and export the graph as .pb
        freeze_export_params = ['--input_type', str('image_tensor'),
                                '--pipeline_config_path', str(tfrecord_config_path),
                                '--trained_checkpoint_prefix', str(model_path + '/model.ckpt-' + num_steps_hyperparam),
                                '--output_directory', str(model_path + '/graph')]
        print('Exporting frozen graph...')
        commandline_util.run_python_script(freezing_script, freeze_export_params)

        if quantize:
            print('Quantizing frozen graph...')
            # freeze and export the graph for tflite processing
            lite_freeze_export_params = ['--pipeline_config_path', str(tfrecord_config_path),
                                         '--trained_checkpoint_prefix',
                                         str(model_path + '/model.ckpt-' + num_steps_hyperparam),
                                         '--output_directory', str(model_path + '/graph'),
                                         '--add_postprocessing_op', str('true')]
            print('Exporting Lite frozen graph...')
            commandline_util.run_python_script(lite_freezing_script, lite_freeze_export_params)

            # quantize and export the tflite graph
            lite_quant_export_params = ['--output_file', str(model_path + '/graph/tflite_quant_graph.tflite'),
                                        '--graph_def_file', str(model_path + '/graph/tflite_graph.pb'),
                                        '--input_shapes', str('1,300,300,3'),
                                        '--input_arrays', str('normalized_input_image_tensor'),
                                        '--output_arrays', str('TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3'),
                                        '--inference_type', str('QUANTIZED_UINT8'),
                                        '--mean_values', str('128'),
                                        '--std_dev_values', str('128'),
                                        '--allow_custom_ops']
            print('Quantizing Lite graph...')
            commandline_util.run_command('tflite_convert', lite_quant_export_params)

        copyfile(tfrecord_label_path, model_path + '/graph')

        graph_files = os.listdir(model_path + '/graph')
        print('Successfully generated graphs: {}'.format(graph_files))

        # A zero exit code causes the job to be marked a Succeeded.
        sys.exit(0)
    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)
